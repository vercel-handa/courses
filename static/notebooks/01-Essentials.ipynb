{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ollama REST API Interactive Testing\n",
        "\n",
        "### Before you begin:\n",
        "- Make sure Ollama is installed on your machine: https://ollama.com/docs/installation\n",
        "- Start the Ollama REST API server locally by running:\n",
        "```bash\n",
        "ollama api start\n",
        "```\n",
        "- By default, the API listens at `http://localhost:11434`.\n",
        "- Ensure you have the `requests` Python package installed:\n",
        "```bash\n",
        "uv install requests\n",
        "```\n",
        "\n",
        "Once the server is running, you can use this notebook to send prompts and get responses interactively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook allows you to send prompts interactively to your local Ollama REST API and get responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from IPython.display import display\n",
        "\n",
        "def ollama_api_chat(model, prompt, api_url=\"http://localhost:11434/v1/chat/completions\", api_key=None):\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    if api_key:\n",
        "        headers[\"Authorization\"] = f\"Bearer {api_key}\"\n",
        "    \n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_tokens\": 150\n",
        "    }\n",
        "    \n",
        "    response = requests.post(api_url, json=data, headers=headers)\n",
        "    response.raise_for_status()\n",
        "    result = response.json()\n",
        "    return result[\"choices\"][0][\"message\"][\"content\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Chat\n",
        "\n",
        "Use the cell below to enter a prompt and get a response from the Ollama model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters\n",
        "model_name = \"llama2\"  # Change this if you want another model\n",
        "api_key = None  # Put your API key here if needed\n",
        "\n",
        "# Prompt input\n",
        "prompt = input(\"Enter your prompt for Ollama: \")\n",
        "\n",
        "try:\n",
        "    response = ollama_api_chat(model_name, prompt, api_key=api_key)\n",
        "    print(\"\\nOllama Response:\")\n",
        "    print(response)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
